{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Aiida"]},{"cell_type":"code","execution_count":35,"metadata":{"tags":[]},"outputs":[],"source":["import subprocess"]},{"cell_type":"code","execution_count":36,"metadata":{"tags":[]},"outputs":[],"source":["# try: \n","#     subprocess.check_output([\"verdi\", \"profile\", \"setup\", \"core.sqlite_dos\", \"-n\", \"--profile-name\", \"test\", \"--email\", \"no@email.com\"])\n","# except: \n","#     pass"]},{"cell_type":"code","execution_count":37,"metadata":{"tags":[]},"outputs":[{"data":{"text/plain":["Profile<uuid='221f3a230d854cdcb071af13c7c3a425' name='workgraph-dev'>"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["from pathlib import Path\n","from ase.build import bulk\n","\n","from aiida import orm, engine, load_profile\n","from aiida.common.exceptions import NotExistent\n","\n","load_profile('workgraph-dev')"]},{"cell_type":"code","execution_count":38,"metadata":{"tags":[]},"outputs":[],"source":["try:\n","    localhost = orm.load_computer('localhost')\n","except NotExistent:\n","    localhost = orm.Computer(\n","        label='localhost',\n","        hostname='localhost',\n","        transport_type='core.local',\n","        scheduler_type='core.direct',\n","        workdir=Path('workdir').absolute().as_posix()\n","    ).store()\n","    localhost.configure()\n","\n","try:\n","    pw_code = orm.load_code('pw@localhost')\n","except NotExistent:\n","    pw_code = orm.InstalledCode(\n","        label='pw',\n","        computer=localhost,\n","        filepath_executable='pw.x',\n","        default_calc_job_plugin='aiida_qe_basic.pw',\n","        prepend_text='export OMP_NUM_THREADS=1'\n","    ).store()"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# ! rabbitmq-server -detached"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["# ! sleep 5"]},{"cell_type":"code","execution_count":41,"metadata":{"tags":[]},"outputs":[],"source":["# results = engine.run(builder)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# results"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# results['properties'].get_dict()"]},{"cell_type":"markdown","metadata":{},"source":["## Equation of State curve - WorkGraph from Xing"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["from aiida_workgraph import task, WorkGraph\n","from ase import Atoms\n","from ase.build import bulk\n","from ase.io.espresso import Namelist\n","from ase.calculators.espresso import Espresso, EspressoProfile\n","# ? from ase_quantumespresso.espresso import Espresso, EspressoProfile -> Renamed this. Why `ase_quantumespresso`?"]},{"cell_type":"markdown","metadata":{},"source":["### Creating the structure"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["\n","atoms = bulk('Al', a=4.05, cubic=True) \n","structure = orm.StructureData(ase=atoms)"]},{"cell_type":"markdown","metadata":{},"source":["### Building blocks taken from `workgraph-collections`"]},{"cell_type":"markdown","metadata":{},"source":["#### `generate_scaled_atoms` and `fit_eos`"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["\n","@task(\n","    outputs=[\n","        {\"name\": \"scaled_atoms\", \"identifier\": \"Namespace\"},\n","        {\"name\": \"volumes\"},\n","    ]\n",")\n","def generate_scaled_atoms(atoms: Atoms, scales: list) -> dict:\n","    \"\"\"Scale the structure by the given scales.\"\"\"\n","    volumes = {}\n","    scaled_atoms = {}\n","    for i in range(len(scales)):\n","        atoms1 = atoms.copy()\n","        atoms1.set_cell(atoms.cell * scales[i], scale_atoms=True)\n","        scaled_atoms[f\"s_{i}\"] = atoms1\n","        volumes[f\"s_{i}\"] = atoms1.get_volume()\n","    return {\"scaled_atoms\": scaled_atoms, \"volumes\": volumes}\n","\n","\n","@task()\n","def fit_eos(volumes: dict, scf_results: dict) -> dict:\n","    \"\"\"Fit the EOS of the data.\"\"\"\n","    from ase.eos import EquationOfState\n","    from ase.units import kJ\n","\n","    volumes_list = []\n","    energies = []\n","    for key, data in scf_results.items():\n","        energy = data[\"energy\"]\n","        energies.append(energy)\n","        volumes_list.append(volumes[key])\n","    #\n","    eos = EquationOfState(volumes_list, energies)\n","    v0, e0, B = eos.fit()\n","    # convert B to GPa\n","    B = B / kJ * 1.0e24\n","    eos = {\"energy unit\": \"eV\", \"v0\": v0, \"e0\": e0, \"B\": B}\n","    return eos\n"]},{"cell_type":"markdown","metadata":{},"source":["#### PwCalculator"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["\n","@task(\n","    outputs=[\n","        {\"name\": \"atoms\"},\n","        {\"name\": \"results\"},\n","    ]\n",")\n","def pw_calculator(\n","    atoms: Atoms,\n","    pseudopotentials: dict,\n","    kpts: list = None,\n","    kspacing: float = None,\n","    command: str = \"pw.x\",\n","    input_data: dict = None,\n","    pseudo_dir: str = \"./pseudopotentials\",\n","    calculation: str = None,\n",") -> dict:\n","    \"\"\"Run a Quantum Espresso calculation on the given atoms object.\"\"\"\n","\n","    input_data = {} if input_data is None else input_data\n","\n","    from ase.io.espresso import Namelist\n","    from ase.calculators.espresso import Espresso, EspressoProfile\n","    \n","    profile = EspressoProfile(command=command, pseudo_dir=pseudo_dir)\n","\n","    input_data = Namelist(input_data)\n","    input_data.to_nested(binary=\"pw\")\n","    # set the calculation type\n","    if calculation:\n","        input_data.setdefault(\"CONTROL\", {})\n","        input_data[\"CONTROL\"][\"calculation\"] = calculation\n","\n","    # Set the output directory\n","    input_data.setdefault(\"CONTROL\", {})\n","    input_data[\"CONTROL\"][\"outdir\"] = \"out\"\n","\n","    calc = Espresso(\n","        profile=profile,\n","        pseudopotentials=pseudopotentials,\n","        input_data=input_data,\n","        kpts=kpts,\n","        kspacing=kspacing,\n","    )\n","\n","    atoms.calc = calc\n","\n","    atoms.get_potential_energy()\n","    results = atoms.calc.results\n","    new_atoms = results.pop(\"atoms\")\n","    # we only update the position and cell of the atoms object\n","    atoms.positions = new_atoms.positions\n","    atoms.cell = new_atoms.cell\n","    # Set atoms.calc to None to avoid pickling error\n","    atoms.calc = None\n","    return {\"atoms\": atoms, \"results\": results}\n"]},{"cell_type":"markdown","metadata":{},"source":["#### `all_scf` function"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["@task.graph_builder(outputs=[{\"name\": \"scf_results\", \"from\": \"context.results\"}])\n","def all_scf(scaled_atoms, scf_inputs):\n","    \"\"\"Run the scf calculation for each atoms.\"\"\"\n","\n","    wg = WorkGraph()\n","    for key, atoms in scaled_atoms.items():\n","        scf = wg.tasks.new(\n","            \"PythonJob\", function=pw_calculator, name=f\"scf_{key}\", atoms=atoms\n","        )\n","        scf.set(scf_inputs)\n","        # save the output parameters to the context\n","        scf.set_context({\"results\": f\"results.{key}\"})\n","    return wg"]},{"cell_type":"markdown","metadata":{},"source":["#### EOS WorkGraph"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["\n","@task.graph_builder(outputs=[{\"name\": \"result\", \"from\": \"fit_eos.result\"}])\n","def eos_workgraph(\n","    atoms: Atoms = None,\n","    command: str = \"pw.x\",\n","    computer: str = \"localhost\",\n","    scales: list = None,\n","    pseudopotentials: dict = None,\n","    pseudo_dir: str = None,\n","    kpts: list = None,\n","    input_data: dict = None,\n","    metadata: dict = None,\n","    run_relax: bool = True,\n","):\n","    \"\"\"Workgraph for EOS calculation.\n","    1. Get the scaled atoms.\n","    2. Run the SCF calculation for each scaled atoms.\n","    3. Fit the EOS.\n","    \"\"\"\n","    from copy import deepcopy\n","\n","    input_data = input_data or {}\n","\n","    wg = WorkGraph(\"EOS\")\n","    # -------- relax -----------\n","    if run_relax:\n","        relax_task = wg.tasks.new(\n","            \"PythonJob\",\n","            function=pw_calculator,\n","            name=\"relax\",\n","            atoms=atoms,\n","            metadata=metadata,\n","            computer=computer,\n","        )\n","        relax_input_data = deepcopy(input_data)\n","        relax_input_data.setdefault(\"CONTROL\", {})\n","        relax_input_data[\"CONTROL\"][\"calculation\"] = \"vc-relax\"\n","        relax_task.set(\n","            {\n","                \"command\": command,\n","                \"input_data\": relax_input_data,\n","                \"kpts\": kpts,\n","                \"pseudopotentials\": pseudopotentials,\n","                \"pseudo_dir\": pseudo_dir,\n","            }\n","        )\n","        atoms = relax_task.outputs[\"atoms\"]\n","    # -------- scale_atoms -----------\n","    scale_atoms_task = wg.tasks.new(\n","        \"PythonJob\",\n","        function=generate_scaled_atoms,\n","        name=\"scale_atoms\",\n","        atoms=atoms,\n","        scales=scales,\n","        computer=computer,\n","        metadata=metadata,\n","    )\n","    # -------- all_scf -----------\n","    all_scf1 = wg.tasks.new(\n","        all_scf,\n","        name=\"all_scf\",\n","        scaled_atoms=scale_atoms_task.outputs[\"scaled_atoms\"],\n","        scf_inputs={\n","            \"command\": command,\n","            \"input_data\": input_data,\n","            \"kpts\": kpts,\n","            \"pseudopotentials\": pseudopotentials,\n","            \"pseudo_dir\": pseudo_dir,\n","            \"metadata\": metadata,\n","            \"computer\": computer,\n","        },\n","    )\n","    # -------- fit_eos -----------\n","    wg.tasks.new(\n","        \"PythonJob\",\n","        function=fit_eos,\n","        name=\"fit_eos\",\n","        volumes=scale_atoms_task.outputs[\"volumes\"],\n","        scf_results=all_scf1.outputs[\"scf_results\"],\n","        computer=computer,\n","        metadata=metadata,\n","    )\n","    return wg\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Actually submit the `WorkGraph`"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WorkGraph process created, PK: 546\n"]}],"source":["\n","# ? metadata dictionary has to be AiiDA data type\n","\n","pseudopotentials = {\"Al\": \"Al.pbe-n-kjpaw_psl.1.0.0.UPF\"}\n","pseudo_dir = \"/home/geiger_j/aiida_projects/workgraph-dev/git-repos/ADIS2023/espresso/pseudo\" # -> Must be string, why not Path?\n","input_data = {\n","    \"system\": {\n","        \"occupations\": \"smearing\",\n","        \"degauss\": 0.02,\n","        \"smearing\": \"cold\",\n","    },\n","}\n","# metadata = orm.Dict({\"options\": {\"prepend_text\": \"export OMP_NUM_THREADS=1\"}})\n","\n","wg = eos_workgraph(\n","    # atoms=atoms,\n","    atoms=atoms,\n","    computer=\"localhost\",\n","    scales=[0.95, 0.98, 1.0, 1.02, 1.05],\n","    command=\"mpirun -np 2 pw.x\",\n","    pseudopotentials=pseudopotentials,\n","    pseudo_dir=pseudo_dir,\n","    input_data=input_data,\n","    kpts=(4, 4, 4),\n","    # metadata=metadata,\n",")\n","# ------------------------- Submit the calculation -------------------\n","# wg.run()\n","wg.submit(wait=True, timeout=200)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
